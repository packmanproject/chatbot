{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth',-1) # ini untuk melihat full column\n",
    "client = MongoClient('localhost', 27017) #ihi host\n",
    "db=client.get_database('fujiatma') # ini nama database sebelumnya create dlu di mongodb atau di robomongo\n",
    "collection=db.get_collection('data')# ini nama collectionnya (misal data)\n",
    "#collection.find_one({ \"question\" : \"Does it fit Nook GlowLight?\"})# ini contoh query saja\n",
    "\n",
    "\n",
    "#cara dump ke mongo\n",
    "#mongoimport --db fujiatma --collection data --file intents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>answerTime</th>\n",
       "      <th>answerType</th>\n",
       "      <th>asin</th>\n",
       "      <th>intents</th>\n",
       "      <th>question</th>\n",
       "      <th>questionType</th>\n",
       "      <th>unixTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a6b45346337ffb0d53c8710</td>\n",
       "      <td>Yes this fits both the nook color and the same-shaped nook tablet</td>\n",
       "      <td>Dec 27, 2013</td>\n",
       "      <td>Y</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Is this cover the one that fits the old nook color? Which I believe is 8x5.</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>1.388131e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a6b45346337ffb0d53c8711</td>\n",
       "      <td>No. The nook color or color tablet</td>\n",
       "      <td>Jan 5, 2015</td>\n",
       "      <td>N</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Does it fit Nook GlowLight?</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>1.420445e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a6b45346337ffb0d53c8712</td>\n",
       "      <td>I don't think so. The nook color is 5 x 8 so not sure anything smaller would stay locked in, but would be close.</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Would it fit Nook 1st Edition? 4.9in x 7.7in ?</td>\n",
       "      <td>open-ended</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a6b45346337ffb0d53c8713</td>\n",
       "      <td>yes</td>\n",
       "      <td>17 days ago</td>\n",
       "      <td>Y</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Will this fit a Nook Color that's 5 x 8?</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a6b45346337ffb0d53c8714</td>\n",
       "      <td>No, the tab is smaller than the 'color'</td>\n",
       "      <td>Feb 10, 2015</td>\n",
       "      <td>N</td>\n",
       "      <td>0594033926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>will this fit the Samsung Galaxy Tab 4 Nook 10.1</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>1.423555e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5a6b45346337ffb0d53c8710   \n",
       "1  5a6b45346337ffb0d53c8711   \n",
       "2  5a6b45346337ffb0d53c8712   \n",
       "3  5a6b45346337ffb0d53c8713   \n",
       "4  5a6b45346337ffb0d53c8714   \n",
       "\n",
       "                                                                                                             answer  \\\n",
       "0  Yes this fits both the nook color and the same-shaped nook tablet                                                  \n",
       "1  No. The nook color or color tablet                                                                                 \n",
       "2  I don't think so. The nook color is 5 x 8 so not sure anything smaller would stay locked in, but would be close.   \n",
       "3  yes                                                                                                                \n",
       "4  No, the tab is smaller than the 'color'                                                                            \n",
       "\n",
       "     answerTime answerType        asin intents  \\\n",
       "0  Dec 27, 2013  Y          0594033926  NaN      \n",
       "1  Jan 5, 2015   N          0594033926  NaN      \n",
       "2  2 days ago    NaN        0594033926  NaN      \n",
       "3  17 days ago   Y          0594033926  NaN      \n",
       "4  Feb 10, 2015  N          0594033926  NaN      \n",
       "\n",
       "                                                                      question  \\\n",
       "0  Is this cover the one that fits the old nook color? Which I believe is 8x5.   \n",
       "1  Does it fit Nook GlowLight?                                                   \n",
       "2  Would it fit Nook 1st Edition? 4.9in x 7.7in ?                                \n",
       "3  Will this fit a Nook Color that's 5 x 8?                                      \n",
       "4  will this fit the Samsung Galaxy Tab 4 Nook 10.1                              \n",
       "\n",
       "  questionType      unixTime  \n",
       "0  yes/no       1.388131e+09  \n",
       "1  yes/no       1.420445e+09  \n",
       "2  open-ended  NaN            \n",
       "3  yes/no      NaN            \n",
       "4  yes/no       1.423555e+09  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=collection.find() # query untuk melihat isi collection\n",
    "data = pd.DataFrame(list(collection.find())) # merubah ke data frame\n",
    "#data=data[data['question']!=np.nan]\n",
    "#data=data.dropna(axis=0, how='all')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak data: 27000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is this cover the one that fits the old nook color? Which I believe is 8x5.</td>\n",
       "      <td>Yes this fits both the nook color and the same-shaped nook tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does it fit Nook GlowLight?</td>\n",
       "      <td>No. The nook color or color tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Would it fit Nook 1st Edition? 4.9in x 7.7in ?</td>\n",
       "      <td>I don't think so. The nook color is 5 x 8 so not sure anything smaller would stay locked in, but would be close.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will this fit a Nook Color that's 5 x 8?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will this fit the Samsung Galaxy Tab 4 Nook 10.1</td>\n",
       "      <td>No, the tab is smaller than the 'color'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      question  \\\n",
       "0  Is this cover the one that fits the old nook color? Which I believe is 8x5.   \n",
       "1  Does it fit Nook GlowLight?                                                   \n",
       "2  Would it fit Nook 1st Edition? 4.9in x 7.7in ?                                \n",
       "3  Will this fit a Nook Color that's 5 x 8?                                      \n",
       "4  will this fit the Samsung Galaxy Tab 4 Nook 10.1                              \n",
       "\n",
       "                                                                                                             answer  \n",
       "0  Yes this fits both the nook color and the same-shaped nook tablet                                                 \n",
       "1  No. The nook color or color tablet                                                                                \n",
       "2  I don't think so. The nook color is 5 x 8 so not sure anything smaller would stay locked in, but would be close.  \n",
       "3  yes                                                                                                               \n",
       "4  No, the tab is smaller than the 'color'                                                                           "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ques_answer=data[['question','answer']][:27000]\n",
    "print \"banyak data:\", len(data_ques_answer)\n",
    "data_ques_answer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preproses: proses jika di jadikan satu\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(corpus):\n",
    "    #melakukan proses lowercase, stopword removal, dan punctuation removal\n",
    "    print \"proses lowercase\"\n",
    "    m=[]\n",
    "\n",
    "    for item in range(len(corpus)):\n",
    "        text=string.lower(corpus['question'].iloc[item])\n",
    "        #jawab=string.lower(corpus['answer'].iloc[item])\n",
    "        corpus['question'].iloc[item]=text  \n",
    "        #corpus['answer'].iloc[item]=jawab\n",
    "\n",
    "    print \"proses stopwords removal\"\n",
    "    cachedStopWords = set(stopwords.words(\"english\"))\n",
    "    for i in range(len(corpus)):\n",
    "        sent=corpus['question'].iloc[i]\n",
    "        kt=\" \".join([word for word in sent.split() if word not in cachedStopWords])\n",
    "        corpus['question'].iloc[i]=kt\n",
    "        \n",
    "    print \"proses punctuation\"\n",
    "    remove=string.punctuation\n",
    "\n",
    "    for i in range(len(corpus)):\n",
    "        sent=data_ques_answer['question'].iloc[i]\n",
    "        kd=' '.join(word.strip(remove) for word in sent.split())\n",
    "        corpus['question'].iloc[i]=kd\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proses lowercase\n",
      "proses stopwords removal\n",
      "proses punctuation\n",
      "jumlah data: 27000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cover one fits old nook color believe 8x5</td>\n",
       "      <td>Yes this fits both the nook color and the same-shaped nook tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fit nook glowlight</td>\n",
       "      <td>No. The nook color or color tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would fit nook 1st edition 4.9in x 7.7in</td>\n",
       "      <td>I don't think so. The nook color is 5 x 8 so not sure anything smaller would stay locked in, but would be close.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fit nook color that's 5 x 8</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fit samsung galaxy tab 4 nook 10.1</td>\n",
       "      <td>No, the tab is smaller than the 'color'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    question  \\\n",
       "0  cover one fits old nook color believe 8x5   \n",
       "1  fit nook glowlight                          \n",
       "2  would fit nook 1st edition 4.9in x 7.7in    \n",
       "3  fit nook color that's 5 x 8                 \n",
       "4  fit samsung galaxy tab 4 nook 10.1          \n",
       "\n",
       "                                                                                                             answer  \n",
       "0  Yes this fits both the nook color and the same-shaped nook tablet                                                 \n",
       "1  No. The nook color or color tablet                                                                                \n",
       "2  I don't think so. The nook color is 5 x 8 so not sure anything smaller would stay locked in, but would be close.  \n",
       "3  yes                                                                                                               \n",
       "4  No, the tab is smaller than the 'color'                                                                           "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normal=preprocess(data_ques_answer)\n",
    "print 'jumlah data:',len(data_normal)\n",
    "data_normal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PENDEKATAN NAIVE BAYES, SVM, MLP [n_data 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    cover one fits old nook color believe 8x5\n",
       "1    fit nook glowlight                       \n",
       "2    would fit nook 1st edition 4.9in x 7.7in \n",
       "3    fit nook color that's 5 x 8              \n",
       "4    fit samsung galaxy tab 4 nook 10.1       \n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data_normal.question[:100])\n",
    "X_train_counts.shape\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape\n",
    "\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "data_normal.question[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Yes this fits both the nook color and the same-shaped nook tablet                                               \n",
       "1    No. The nook color or color tablet                                                                              \n",
       "2    I don't think so. The nook color is 5 x 8 so not sure anything smaller would stay locked in, but would be close.\n",
       "3    yes                                                                                                             \n",
       "4    No, the tab is smaller than the 'color'                                                                         \n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb = MultinomialNB().fit(X_train_tfidf, data_normal.answer[:100])\n",
    "clf_svm = LinearSVC().fit(X_train_tfidf, data_normal.answer[:100])\n",
    "clf_mlp = MLPClassifier().fit(X_train_tfidf, data_normal.answer[:100])\n",
    "data_normal.answer[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n",
      "0.99\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "print clf_nb.score(X_train_tfidf, data_normal.answer[:100])\n",
    "print clf_svm.score(X_train_tfidf, data_normal.answer[:100])\n",
    "print clf_mlp.score(X_train_tfidf, data_normal.answer[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pertanyaan:\n",
      "good morning\n",
      "jawab:\n",
      "[u'Yes, you can also use the Amazon Kindle app.']\n"
     ]
    }
   ],
   "source": [
    "docs_new = 'good morning'\n",
    "print 'pertanyaan:\\n',docs_new\n",
    "docs_new=string.lower(docs_new)\n",
    "docs_new1=[]\n",
    "docs_new1.append(docs_new)\n",
    "docs_new1\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new1)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf_mlp.predict(X_new_tfidf)\n",
    "print \"jawab:\\n\", predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'fit samsung galaxy tab 4 nook 10.1'], \n",
       "      dtype='<U114')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_counts = count_vect.transform(docs_new1)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PENDEKATAN SEQ2SEQ- Code In python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-71d1234573f3>, line 125)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-71d1234573f3>\"\u001b[0;36m, line \u001b[0;32m125\u001b[0m\n\u001b[0;31m    print 'ok'\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''Sequence to sequence example in Keras (character-level).\n",
    "\n",
    "This script demonstrates how to implement a basic character-level\n",
    "sequence-to-sequence model. We apply it to translating\n",
    "short English sentences into short French sentences,\n",
    "character-by-character. Note that it is fairly unusual to\n",
    "do character-level machine translation, as word-level\n",
    "models are more common in this domain.\n",
    "\n",
    "# Summary of the algorithm\n",
    "\n",
    "- We start with input sequences from a domain (e.g. English sentences)\n",
    "    and correspding target sequences from another domain\n",
    "    (e.g. French sentences).\n",
    "- An encoder LSTM turns input sequences to 2 state vectors\n",
    "    (we keep the last LSTM state and discard the outputs).\n",
    "- A decoder LSTM is trained to turn the target sequences into\n",
    "    the same sequence but offset by one timestep in the future,\n",
    "    a training process called \"teacher forcing\" in this context.\n",
    "    Is uses as initial state the state vectors from the encoder.\n",
    "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "    given `targets[...t]`, conditioned on the input sequence.\n",
    "- In inference mode, when we want to decode unknown input sequences, we:\n",
    "    - Encode the input sequence into state vectors\n",
    "    - Start with a target sequence of size 1\n",
    "        (just the start-of-sequence character)\n",
    "    - Feed the state vectors and 1-char target sequence\n",
    "        to the decoder to produce predictions for the next character\n",
    "    - Sample the next character using these predictions\n",
    "        (we simply use argmax).\n",
    "    - Append the sampled character to the target sequence\n",
    "    - Repeat until we generate the end-of-sequence character or we\n",
    "        hit the character limit.\n",
    "\n",
    "# Data download\n",
    "\n",
    "English to French sentence pairs.\n",
    "http://www.manythings.org/anki/fra-eng.zip\n",
    "\n",
    "Lots of neat sentence pairs datasets can be found at:\n",
    "http://www.manythings.org/anki/\n",
    "\n",
    "# References\n",
    "\n",
    "- Sequence to Sequence Learning with Neural Networks\n",
    "    https://arxiv.org/abs/1409.3215\n",
    "- Learning Phrase Representations using\n",
    "    RNN Encoder-Decoder for Statistical Machine Translation\n",
    "    https://arxiv.org/abs/1406.1078\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'fra.txt'\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "print 'ok'\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('s2s.h5')\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
